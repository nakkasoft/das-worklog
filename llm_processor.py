import os
import json
from openai import AzureOpenAI


class LLMProcessor:
    """LLMì„ ì´ìš©í•œ ì›Œí¬ë¡œê·¸ ë°ì´í„° ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config):
        """
        LLMProcessor ì´ˆê¸°í™”
        
        Args:
            config (dict): Azure OpenAI ì„¤ì • ì •ë³´
        """
        self.config = config
        self.client = AzureOpenAI(
            azure_endpoint=config["azure_openai_endpoint"],
            api_key=config["azure_openai_api_key"],
            api_version=config["azure_openai_api_version"],
        )
    
    def find_md_file(self, directory_path):
        """
        ë””ë ‰í† ë¦¬ì—ì„œ ì£¼ê°„ ë³´ê³  í…œí”Œë¦¿ .md íŒŒì¼ì„ ì°¾ê¸°
        
        Args:
            directory_path (str): ê²€ìƒ‰í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            
        Returns:
            str or None: ì°¾ì€ .md íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ, ì—†ìœ¼ë©´ None
        """
        try:
            # ìš°ì„ ìˆœìœ„ íŒŒì¼ë“¤ (ì£¼ê°„ ë³´ê³  ê´€ë ¨)
            priority_files = [
                'weekly_report_template.md',
                'weekly_report.md',
                'template.md'
            ]
            
            # templates ë””ë ‰í† ë¦¬ë„ í™•ì¸
            templates_dir = os.path.join(directory_path, 'templates')
            search_dirs = [directory_path]
            if os.path.exists(templates_dir):
                search_dirs.append(templates_dir)
            
            # ìš°ì„ ìˆœìœ„ íŒŒì¼ë¶€í„° ê²€ìƒ‰
            for search_dir in search_dirs:
                for priority_file in priority_files:
                    file_path = os.path.join(search_dir, priority_file)
                    if os.path.exists(file_path):
                        print(f"âœ… ì£¼ê°„ ë³´ê³  í…œí”Œë¦¿ ë°œê²¬: {file_path}")
                        return file_path
            
            # ìš°ì„ ìˆœìœ„ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì¼ë°˜ .md íŒŒì¼ ê²€ìƒ‰ (readme.md ì œì™¸)
            for search_dir in search_dirs:
                if os.path.exists(search_dir):
                    for file in os.listdir(search_dir):
                        if (file.lower().endswith('.md') and 
                            file.lower() not in ['readme.md', 'changelog.md', 'license.md']):
                            file_path = os.path.join(search_dir, file)
                            print(f"ğŸ“„ MD íŒŒì¼ ë°œê²¬: {file_path}")
                            return file_path
            
            print("âš ï¸ ì£¼ê°„ ë³´ê³  í…œí”Œë¦¿ MD íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        except Exception as e:
            raise Exception(f"ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def read_md_file(self, md_file_path):
        """
        .md íŒŒì¼ ì½ê¸°
        
        Args:
            md_file_path (str): .md íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: íŒŒì¼ ë‚´ìš©
        """
        try:
            print(f"ğŸ“– MD íŒŒì¼ ì½ëŠ” ì¤‘: {md_file_path}")
            
            if not os.path.exists(md_file_path):
                raise Exception(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {md_file_path}")
            
            with open(md_file_path, 'r', encoding='utf-8') as file:
                content = file.read()
                
            if not content.strip():
                print("âš ï¸ MD íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return ""
            
            print(f"âœ… MD íŒŒì¼ ì½ê¸° ì™„ë£Œ ({len(content)} ë¬¸ì)")
            return content
            
        except UnicodeDecodeError:
            # UTF-8ë¡œ ì½ê¸° ì‹¤íŒ¨ì‹œ ë‹¤ë¥¸ ì¸ì½”ë”© ì‹œë„
            try:
                with open(md_file_path, 'r', encoding='cp949') as file:
                    content = file.read()
                print(f"âœ… MD íŒŒì¼ ì½ê¸° ì™„ë£Œ (CP949 ì¸ì½”ë”©, {len(content)} ë¬¸ì)")
                return content
            except Exception as e:
                raise Exception(f"íŒŒì¼ ì½ê¸° ì¤‘ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
        except Exception as e:
            raise Exception(f"íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def generate_worklog_summary(self, username, worklog_data, md_content=None):
        """
        ì›Œí¬ë¡œê·¸ ë°ì´í„°ë¥¼ LLMìœ¼ë¡œ ìš”ì•½
        
        Args:
            username (str): ì‚¬ìš©ìëª…
            worklog_data (dict): ìˆ˜ì§‘ëœ ì›Œí¬ë¡œê·¸ ë°ì´í„°
            md_content (str, optional): ì¶”ê°€ ì°¸ê³ ìš© ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë‚´ìš©
            
        Returns:
            str: LLMì´ ìƒì„±í•œ ìš”ì•½ ë‚´ìš©
        """
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt_content = self._build_prompt(username, worklog_data, md_content)
            
            # Azure OpenAI API í˜¸ì¶œ
            completion = self.client.chat.completions.create(
                model=self.config["azure_openai_chat_deployment"],
                messages=[
                    {
                        "role": "user",
                        "content": prompt_content
                    }
                ],
                max_completion_tokens=10000,
            )
            
            return completion.choices[0].message.content
            
        except Exception as e:
            raise Exception(f"LLM ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def _build_prompt(self, username, worklog_data, md_content=None):
        """
        LLM ìš”ì²­ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
        Args:
            username (str): ì‚¬ìš©ìëª…
            worklog_data (dict): ì›Œí¬ë¡œê·¸ ë°ì´í„°
            md_content (str, optional): ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë‚´ìš©
            
        Returns:
            str: êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸
        """
        # ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """ë‹¹ì‹ ì€ ì£¼ê°„ ë³´ê³ ë¥¼ ì•„ì£¼ ì˜ ì •ë¦¬í•˜ëŠ” ì£¼ê°„ ë³´ê³  ë§ˆìŠ¤í„°ì…ë‹ˆë‹¤. 
        ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ê°„ ë³´ê³ ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.

        ì£¼ê°„ ë³´ê³  ì‘ì„± ê°€ì´ë“œë¼ì¸:
        1. Issue í˜„í™©ì€ ë‚´ê°€ ìˆ˜ì •í•œ Issueë§Œ í¬í•¨ë©ë‹ˆë‹¤. ë‚´ê°€ Resolve ì²˜ë¦¬ë¥¼ í–ˆê±°ë‚˜, ë‚˜ì—ê²Œ Assignëœ Issueë“¤ë§Œ Count í•´ì£¼ì„¸ìš”.
        2. ì£¼ìš” ì²˜ë¦¬ Issueë‚˜ ì£¼ìš” ì”ì—¬ IssueëŠ” Issueì˜ ì œëª©ì„ ë„£ì–´ ì£¼ê³ , Issueì˜ ë‚´ìš©ì„ ê°„ëµí•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. 1~2ì¤„ ì •ë„ê°€ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
        3. ë‚´ê°€ í•´ë‹¹ Issueì— ëŒ€í•´ì„œ ìˆ˜í–‰í•œ ì‘ì—…ë“¤ì„ Comment Baseë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        4. ê¸°ìˆ  ê´€ë ¨ Issueë¼ë©´ ì–´ëŠ ì •ë„ ê¸°ìˆ ê´€ë ¨ ë‚´ìš©ì´ ë“¤ì–´ê°€ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

        """
        
        # MD íŒŒì¼ ì–‘ì‹ì´ ìˆìœ¼ë©´ ì¶”ê°€
        if md_content:
            system_prompt += f"""
            === ì£¼ê°„ ë³´ê³  ì–‘ì‹ (ë‹¤ìŒ ì–‘ì‹ì— ë§ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”) ===
            {md_content}

            === ì–‘ì‹ ë ===

            ìœ„ ì–‘ì‹ì— ë§ì¶°ì„œ ì•„ë˜ ì›Œí¬ë¡œê·¸ ë°ì´í„°ë¥¼ ì •ë¦¬í•´ì„œ ì£¼ê°„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
        
        # ì›Œí¬ë¡œê·¸ ë°ì´í„° ì¶”ê°€
        prompt_parts = [
            system_prompt,
            f"\n=== ì›Œí¬ë¡œê·¸ ë°ì´í„° ===\n",
            f"ì‚¬ìš©ì: {username}\n\n",
            f"ğŸ“‹ JIRA í™œë™ ë°ì´í„° ({len(worklog_data['jira_data'])}ê°œ í•­ëª©):\n",
            f"{json.dumps(worklog_data['jira_data'], ensure_ascii=False, indent=2)}\n\n",
            f"ğŸ“ CONFLUENCE í™œë™ ë°ì´í„° ({len(worklog_data['confluence_data'])}ê°œ í•­ëª©):\n",
            f"{json.dumps(worklog_data['confluence_data'], ensure_ascii=False, indent=2)}\n\n",
            f"ğŸ” GERRIT ë¦¬ë·° ë°ì´í„° ({len(worklog_data['gerrit_reviews'])}ê°œ í•­ëª©):\n",
            f"{json.dumps(worklog_data['gerrit_reviews'], ensure_ascii=False, indent=2)}\n\n",
            f"ğŸ’¬ GERRIT ëŒ“ê¸€ ë°ì´í„° ({len(worklog_data['gerrit_comments'])}ê°œ í•­ëª©):\n",
            f"{json.dumps(worklog_data['gerrit_comments'], ensure_ascii=False, indent=2)}\n\n"
        ]
        
        # ì´ë©”ì¼ ë°ì´í„° ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if 'email_summaries' in worklog_data and worklog_data['email_summaries']:
            prompt_parts.extend([
                f"ğŸ“§ ë°œì†¡ ì´ë©”ì¼ ìš”ì•½ ë°ì´í„° ({len(worklog_data['email_summaries'])}ê°œ í•­ëª©):\n",
                f"{json.dumps(worklog_data['email_summaries'], ensure_ascii=False, indent=2)}\n\n"
            ])
        
        prompt_parts.append("ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ê°„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.")
        
        return "".join(prompt_parts)
    
    def process_worklog_with_md_file(self, username, worklog_data, directory_path):
        """
        ì›Œí¬ë¡œê·¸ ë°ì´í„°ì™€ MD íŒŒì¼ì„ í•¨ê»˜ ì²˜ë¦¬í•˜ì—¬ ìš”ì•½ ìƒì„±
        
        Args:
            username (str): ì‚¬ìš©ìëª…
            worklog_data (dict): ì›Œí¬ë¡œê·¸ ë°ì´í„°
            directory_path (str): MD íŒŒì¼ì„ ì°¾ì„ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            
        Returns:
            dict: ì²˜ë¦¬ ê²°ê³¼ {'success': bool, 'summary': str, 'md_file': str, 'md_content': str, 'error': str}
        """
        result = {
            'success': False,
            'summary': None,
            'md_file': None,
            'md_content': None,
            'error': None
        }
        
        try:
            print(f"ğŸ” MD íŒŒì¼ ê²€ìƒ‰ ì‹œì‘: {directory_path}")
            
            # MD íŒŒì¼ ì°¾ê¸°
            md_file = self.find_md_file(directory_path)
            
            if md_file:
                print(f"ğŸ“„ MD íŒŒì¼ ë°œê²¬: {md_file}")
                
                # MD íŒŒì¼ ì½ê¸°
                md_content = self.read_md_file(md_file)
                result['md_file'] = md_file
                result['md_content'] = md_content
                
                print(f"âœ… MD í…œí”Œë¦¿ì´ ìˆìŠµë‹ˆë‹¤. í…œí”Œë¦¿ ê¸°ë°˜ìœ¼ë¡œ ì£¼ê°„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                print(f"ğŸ“ í…œí”Œë¦¿ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {md_content[:200]}...")
                
                # LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± (MD í…œí”Œë¦¿ í¬í•¨)
                summary = self.generate_worklog_summary(username, worklog_data, md_content)
                result['summary'] = summary
                result['success'] = True
                
            else:
                print("âš ï¸ MD í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ì£¼ê°„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                
                # MD íŒŒì¼ì´ ì—†ì–´ë„ ì›Œí¬ë¡œê·¸ë§Œìœ¼ë¡œ ìš”ì•½ ìƒì„±
                summary = self.generate_worklog_summary(username, worklog_data)
                result['summary'] = summary
                result['success'] = True
                
        except Exception as e:
            error_msg = f"ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"
            print(f"âŒ {error_msg}")
            result['error'] = error_msg
            
        return result


def create_llm_processor(config_file_path):
    """
    ì„¤ì • íŒŒì¼ì—ì„œ LLMProcessor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    Args:
        config_file_path (str): user_config.json íŒŒì¼ ê²½ë¡œ
        
    Returns:
        LLMProcessor: ì´ˆê¸°í™”ëœ LLMProcessor ì¸ìŠ¤í„´ìŠ¤
        
    Raises:
        Exception: ì„¤ì • íŒŒì¼ ì˜¤ë¥˜ ë˜ëŠ” LLMProcessor ìƒì„± ì‹¤íŒ¨
    """
    try:
        with open(config_file_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # í•„ìˆ˜ í‚¤ í™•ì¸
        required_keys = [
            "azure_openai_endpoint",
            "azure_openai_api_key", 
            "azure_openai_api_version",
            "azure_openai_chat_deployment"
        ]
        
        missing_keys = [key for key in required_keys if not config.get(key)]
        if missing_keys:
            raise Exception(f"ì„¤ì • íŒŒì¼ì— í•„ìˆ˜ Azure OpenAI ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_keys}")
        
        return LLMProcessor(config)
        
    except FileNotFoundError:
        raise Exception(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_file_path}")
    except json.JSONDecodeError as e:
        raise Exception(f"ì„¤ì • íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        raise Exception(f"LLMProcessor ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ì˜ˆì œ ì‚¬ìš©ë²•
    try:
        # ì„¤ì • íŒŒì¼ì—ì„œ LLMProcessor ìƒì„±
        processor = create_llm_processor("user_config.json")
        
        # ì˜ˆì œ ì›Œí¬ë¡œê·¸ ë°ì´í„°
        sample_data = {
            'jira_data': [],
            'confluence_data': [],
            'gerrit_reviews': [],
            'gerrit_comments': []
        }
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ MD íŒŒì¼ê³¼ í•¨ê»˜ ì²˜ë¦¬
        result = processor.process_worklog_with_md_file(
            username="test_user",
            worklog_data=sample_data,
            directory_path="./templates"
        )
        
        if result['success']:
            print("âœ“ ì²˜ë¦¬ ì„±ê³µ!")
            if result['md_file']:
                print(f"  ì‚¬ìš©ëœ MD íŒŒì¼: {result['md_file']}")
            print(f"  ìš”ì•½ ê¸¸ì´: {len(result['summary'])}ì")
        else:
            print(f"âœ— ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")
            
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")
